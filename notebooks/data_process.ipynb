{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def crop_image(image, padding=50):\n",
    "    \"\"\"\n",
    "    crop the black block\n",
    "    :param image:(H,W)\n",
    "    :param padding:int\n",
    "    :return:image:(H_,W_) bias [x,y]\n",
    "    \"\"\"\n",
    "    assert (len(image.shape)==2)\n",
    "    H, W = image.shape[0],image.shape[1]\n",
    "    ind = list(np.nonzero(image))\n",
    "    max_y,min_y = int(np.max(ind[0])),int(np.min(ind[0]))\n",
    "    max_x,min_x = int(np.max(ind[1])),int(np.min(ind[1]))\n",
    "    min_x = max(min_x-padding,0)\n",
    "    min_y = max(min_y-padding,0)\n",
    "    max_x = min((max_x+padding),W)\n",
    "    max_y = min((max_y+padding),H)\n",
    "    cropped = image[min_y:max_y, min_x:max_x]\n",
    "    bias = np.array([min_x,min_y])\n",
    "    return cropped,bias\n",
    "\n",
    "\n",
    "def get_contours_points(image):\n",
    "    \"\"\"\n",
    "    :param image: (H,W)\n",
    "    :return: (N,2)\n",
    "    \"\"\"\n",
    "    assert (len(image.shape)==2)\n",
    "    ret, binary = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(binary,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    xcnts = np.vstack((x.reshape(-1,2) for x in contours))\n",
    "    return xcnts\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23075/563374039.py:34: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  xcnts = np.vstack((x.reshape(-1,2) for x in contours))\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0ï¼šblack 1:white\n",
    "\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "from src.dataset.linemod_2d import read_scannet_gray\n",
    "from src.utils.plotting import make_matching_figure\n",
    "data_dir = \"/home/gzr/Data/linemod_2d/DATA/steel\"\n",
    "image_id = \"00000\"\n",
    "image_dir = os.path.join(data_dir,image_id)\n",
    "image_path = os.path.join(image_dir,'matchedMask.jpg')\n",
    "\n",
    "\n",
    "img_mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "contours_points = get_contours_points(img_mask)\n",
    "\n",
    "img_mask ,bias = crop_image(img_mask, padding=20)\n",
    "\n",
    "\n",
    "# print(img_mask.shape)\n",
    "# img_mask = cv2.resize(img_mask, (400,200))\n",
    "img_mask = cv2.cvtColor(img_mask, cv2.COLOR_BGR2RGB)\n",
    "print(len(bias))\n",
    "np.savetxt(os.path.join(image_dir,'bias.txt'),bias,fmt='%i')\n",
    "\n",
    "plt.imshow(img_mask)\n",
    "plt.show()\n",
    "cv2.imwrite(os.path.join(image_dir,'template.jpg'),img_mask)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3228/2824106850.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIMREAD_GRAYSCALE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0mimg_size\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0;36m512\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m image0, mask0, scale0 = read_megadepth_gray(\n\u001B[0m\u001B[1;32m     14\u001B[0m             mask_path, img_size, None, True, None)\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/Template_Matching/src/utils/dataset.py\u001B[0m in \u001B[0;36mread_megadepth_gray\u001B[0;34m(path, resize, df, padding, augment_fn)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m     \u001B[0;31m# resize image\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 109\u001B[0;31m     \u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    110\u001B[0m     \u001B[0mw_new\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_resized_wh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m     \u001B[0mw_new\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_divisible_wh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mw_new\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh_new\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from src.utils.dataset import read_megadepth_gray, read_megadepth_depth,pad_bottom_right\n",
    "import matplotlib.cm as cm\n",
    "data_dir = \"/home/gzr/Data/linemod_2d/DATA/steel\"\n",
    "image_id = \"00003\"\n",
    "image_dir = os.path.join(data_dir,image_id)\n",
    "\n",
    "mask_path = os.path.join(image_dir,'template.jpg')\n",
    "image_path = os.path.join(image_dir,'localObjImg.jpg')\n",
    "\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "img_size  = 512\n",
    "image0, mask0, scale0 = read_megadepth_gray(\n",
    "            mask_path, img_size, None, True, None)\n",
    "\n",
    "\n",
    "image1, mask1, scale1 = read_megadepth_gray(\n",
    "            image_path, img_size, None, True, None)\n",
    "\n",
    "image0 = cv2.resize(mask,dsize=(0,0),fx=1/float(scale1[0]),fy=1/float(scale1[1]))\n",
    "image0, mask = pad_bottom_right(image0, img_size, ret_mask=True)\n",
    "\n",
    "print(image0.shape)\n",
    "bias = np.loadtxt(os.path.join(image_dir,'bias.txt'))\n",
    "\n",
    "mkpts0 = np.array([[310,25],[10,30]]) # x,y\n",
    "mkpts1 = mkpts0 + [bias[0]/scale1[0],bias[1]/scale1[1]]\n",
    "mconf = [0.2,1]\n",
    "color = cm.jet(mconf)\n",
    "print(scale1)\n",
    "# fig = make_matching_figure(mask, image, mkpts0, mkpts1, color)\n",
    "fig = make_matching_figure(image0.squeeze(), image1.squeeze(), mkpts0, mkpts1, color)\n",
    "plt.savefig(os.path.join(image_dir,'a.jpg'), bbox_inches='tight', pad_inches=0,figsize=(1000,1000))\n",
    "plt.close()\n",
    "fig\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000 \t\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_6666/1631860166.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     46\u001B[0m     \u001B[0mimage_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf'{i:05d}'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_id\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'\\t'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m     \u001B[0mprocess_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;31m# f=open(\"img_list.txt\",\"w\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;31m# for i in range(8166):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_6666/1631860166.py\u001B[0m in \u001B[0;36mprocess_image\u001B[0;34m(image_id)\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0mimg_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIMREAD_GRAYSCALE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0mimg_mask\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0mbias\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcrop_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m16\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m     \u001B[0mimg_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCOLOR_BGR2RGB\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msavetxt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'bias.txt'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfmt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'%i'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_6666/1631860166.py\u001B[0m in \u001B[0;36mcrop_image\u001B[0;34m(image, padding)\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mH_\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW_\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \"\"\"\n\u001B[0;32m---> 19\u001B[0;31m     \u001B[0;32massert\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m     \u001B[0mH\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mW\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mind\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# batch process\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from src.dataset.linemod_2d import read_scannet_gray\n",
    "from src.utils.plotting import make_matching_figure\n",
    "data_dir = \"/home/gzr/Data/linemod_2d/DATA/steel_train\"\n",
    "\n",
    "def crop_image(image, padding=50):\n",
    "    \"\"\"\n",
    "    crop the black block\n",
    "    :param image:(H,W)\n",
    "    :param padding:int\n",
    "    :return:image:(H_,W_) bias [x,y]\n",
    "    \"\"\"\n",
    "    assert (len(image.shape)==2)\n",
    "    H, W = image.shape[0],image.shape[1]\n",
    "    ind = list(np.nonzero(image))\n",
    "    max_y,min_y = int(np.max(ind[0])),int(np.min(ind[0]))\n",
    "    max_x,min_x = int(np.max(ind[1])),int(np.min(ind[1]))\n",
    "    min_x = max(min_x-padding,0)\n",
    "    min_y = max(min_y-padding,0)\n",
    "    max_x = min((max_x+padding),W)\n",
    "    max_y = min((max_y+padding),H)\n",
    "    cropped = image[min_y:max_y, min_x:max_x]\n",
    "    bias = np.array([min_x,min_y])\n",
    "    return cropped,bias\n",
    "\n",
    "\n",
    "def process_image(image_id):\n",
    "    image_dir = os.path.join(data_dir,image_id)\n",
    "    image_path = os.path.join(image_dir,'matchedMask.jpg')\n",
    "    img_mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    img_mask ,bias = crop_image(img_mask, padding=20)\n",
    "    img_mask = cv2.cvtColor(img_mask, cv2.COLOR_BGR2RGB)\n",
    "    np.savetxt(os.path.join(image_dir,'bias.txt'),bias,fmt='%i')\n",
    "    # plt.imshow(img_mask)\n",
    "    # plt.show()\n",
    "    cv2.imwrite(os.path.join(image_dir,'template.jpg'),img_mask)\n",
    "\n",
    "for i in range(0,8166):\n",
    "    image_id = f'{i:05d}'\n",
    "    print(image_id,'\\t')\n",
    "    process_image(image_id)\n",
    "# f=open(\"img_list.txt\",\"w\")\n",
    "# for i in range(8166):\n",
    "#\n",
    "#     image_id = f'{i:05d}'\n",
    "#     f.write(image_id+'\\n')\n",
    "# f.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,7):\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 2167)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('/home/gzr/Data/linemod_2d/DATA/steel_test/08156/matchedEdge.jpg',0)\n",
    "print(image.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}